# 猪打架检测系统 - 完整使用说明

## 📁 文件清单

### 核心功能文件

| 文件名 | 功能说明 | 何时使用 |
|--------|----------|----------|
| `track_with_fight_detection.py` | 单视频检测与评估 | 测试单个视频，调试参数 |
| `batch_evaluate.py` | 批量视频评估 | 评估整个测试集 |
| `create_ground_truth.py` | GT标注工具 | 创建或更新Ground Truth |
| `visualize_results.py` | 结果可视化工具 | 查看和分析检测结果 |

### 辅助文件

| 文件名 | 说明 |
|--------|------|
| `README_fight_detection.md` | 完整技术文档 |
| `QUICKSTART.md` | 快速入门指南 |
| `ground_truth_example.json` | GT文件格式示例 |
| `track.py` | 原始跟踪脚本（保留） |

---

## 🔄 完整工作流程

```
┌─────────────────────────────────────────────────────────┐
│                    准备阶段                              │
└─────────────────────────────────────────────────────────┘
                          │
                          ▼
         ┌────────────────────────────────┐
         │  1. 收集测试视频                │
         │     - 包含打架行为的视频         │
         │     - 放在同一目录下            │
         └────────────────────────────────┘
                          │
                          ▼
         ┌────────────────────────────────┐
         │  2. 创建Ground Truth            │
         │                                 │
         │  python create_ground_truth.py │
         │    --video-dir ./test_videos   │
         │    --mode interactive          │
         │    --output ground_truth.json  │
         └────────────────────────────────┘
                          │
┌─────────────────────────────────────────────────────────┐
│                    调优阶段                              │
└─────────────────────────────────────────────────────────┘
                          │
                          ▼
         ┌────────────────────────────────┐
         │  3. 单视频测试（调参）          │
         │                                 │
         │  python track_with_fight_      │
         │    detection.py                │
         │    --source video1.mp4         │
         │    --gt-file ground_truth.json │
         │    --window-size 30            │
         │    --stride 15                 │
         │    --show                      │
         └────────────────────────────────┘
                          │
                          ▼
         ┌────────────────────────────────┐
         │  4. 查看结果并调整参数          │
         │                                 │
         │  python visualize_results.py   │
         │    --video video1.mp4          │
         │    --pred results/             │
         │      video1_predictions.json   │
         │    --gt ground_truth.json      │
         └────────────────────────────────┘
                          │
                          ▼
            ┌─────────────────────┐
            │  F1分数满意？        │
            └─────────────────────┘
              ↓ 否            是 ↓
         重新调参              继续
              │                 │
              └─────────┬───────┘
                        │
┌─────────────────────────────────────────────────────────┐
│                    评估阶段                              │
└─────────────────────────────────────────────────────────┘
                        │
                        ▼
         ┌────────────────────────────────┐
         │  5. 批量评估全部测试集          │
         │                                 │
         │  python batch_evaluate.py      │
         │    --weights best.pt           │
         │    --video-dir ./test_videos   │
         │    --gt-file ground_truth.json │
         │    --window-size 30            │
         │    --stride 15                 │
         │    --output-dir final_results  │
         └────────────────────────────────┘
                        │
                        ▼
         ┌────────────────────────────────┐
         │  6. 分析报告                    │
         │                                 │
         │  查看:                          │
         │  - final_results/              │
         │    evaluation_report.txt       │
         │  - final_results/              │
         │    overall_evaluation.json     │
         └────────────────────────────────┘
                        │
                        ▼
                   ┌────────┐
                   │  完成   │
                   └────────┘
```

---

## 🎯 典型使用场景

### 场景1: 首次使用 - 创建GT并测试

```bash
# 步骤1: 标注第一个视频
python create_ground_truth.py \
    --video pig_fight_001.mp4 \
    --mode interactive \
    --output gt.json

# 步骤2: 运行检测
python track_with_fight_detection.py \
    --weights runs/train/v10-APConv-AssemFormer-HSFPN-ATFLm_exp/weights/best.pt \
    --source pig_fight_001.mp4 \
    --gt-file gt.json \
    --show

# 步骤3: 可视化结果
python visualize_results.py \
    --video pig_fight_001.mp4 \
    --pred fight_detection_results/pig_fight_001_predictions.json \
    --gt gt.json
```

### 场景2: 批量标注多个视频

```bash
# 一次性标注所有视频
python create_ground_truth.py \
    --video-dir ./test_videos \
    --mode interactive \
    --output ground_truth.json
```

操作流程：
1. 视频自动播放
2. 看到打架开始按 `S` 键
3. 打架结束按 `E` 键
4. 完成一个视频后自动进入下一个
5. 全部完成后保存到 `ground_truth.json`

### 场景3: 参数调优

```bash
# 测试不同参数组合
for ws in 20 30 40; do
  for st in 10 15 20; do
    echo "Testing window_size=$ws, stride=$st"
    python track_with_fight_detection.py \
      --source test_video.mp4 \
      --gt-file gt.json \
      --window-size $ws \
      --stride $st \
      --output-dir results_ws${ws}_st${st}
  done
done

# 比较结果，选择最佳参数
```

### 场景4: 完整评估流程

```bash
# 使用最佳参数评估全部测试集
python batch_evaluate.py \
    --weights best.pt \
    --video-dir ./test_videos \
    --gt-file ground_truth.json \
    --window-size 30 \
    --stride 15 \
    --distance-threshold 100 \
    --speed-threshold 50 \
    --min-fight-duration 15 \
    --output-dir final_evaluation

# 查看总体报告
cat final_evaluation/evaluation_report.txt

# 可视化各个视频（可选）
for video in test_videos/*.mp4; do
  basename=$(basename "$video" .mp4)
  python visualize_results.py \
    --video "$video" \
    --pred "final_evaluation/${basename}_predictions.json" \
    --gt ground_truth.json \
    --output "visualizations/${basename}_visualized.mp4" \
    --no-show
done
```

---

## 📊 Ground Truth 格式详解

### 格式1: 直接使用帧号（推荐）

```json
{
  "video1.mp4": [
    [50, 180],
    [300, 450]
  ],
  "video2.mp4": [
    [100, 250]
  ]
}
```

**说明**:
- 每个视频对应一个列表
- 每个元素是 `[开始帧, 结束帧]`
- 帧号从0开始计数

**优点**: 精确，不受帧率影响

### 格式2: 使用时间（秒）

```json
{
  "fps": 30,
  "video1.mp4": [
    [1.67, 6.0],
    [10.0, 15.0]
  ],
  "video2.mp4": [
    [3.33, 8.33]
  ]
}
```

**说明**:
- 需要提供 `fps` 字段
- 时间以秒为单位
- 自动转换为帧号 = 时间 × fps

**优点**: 更直观，便于人工标注

### 如何选择？

- **使用帧号**: 如果从视频编辑软件或自动标注工具导出
- **使用时间**: 如果手工观看视频标注

---

## 🔧 参数调优指南

### 核心参数含义

#### 1. window_size（窗口大小）

**含义**: 一次分析多少帧来判断是否打架

**影响**:
- 太小: 容易受噪声干扰，判断不稳定
- 太大: 时间定位不准确

**建议值**:
- 30 FPS 视频: 20-40 帧（约0.7-1.3秒）
- 25 FPS 视频: 15-35 帧
- 根据实际打架平均持续时间调整

#### 2. stride（滑动步长）

**含义**: 窗口每次移动多少帧

**影响**:
- 太小: 计算量大，但检测更准确
- 太大: 可能遗漏短暂打架

**建议值**:
- window_size 的 1/2 或 1/3
- 精细检测: stride = 5-10
- 快速检测: stride = 15-20

#### 3. distance_threshold（距离阈值）

**含义**: 多近算"接触"（像素）

**影响**:
- 太小: 只有贴很近才算，可能漏检
- 太大: 只要靠近就算，误检增多

**如何确定**:
1. 打开几个打架视频
2. 截图测量打架时两只猪的距离
3. 取平均值

**参考值**:
- 640x480 视频: 60-100
- 1920x1080 视频: 150-250

#### 4. speed_threshold（速度阈值）

**含义**: 移动多快算"剧烈运动"

**影响**:
- 太小: 正常走动也算，误检多
- 太大: 打架不够激烈会漏检

**如何确定**:
1. 观察正常行为的移动速度
2. 观察打架时的移动速度
3. 设置在两者之间

#### 5. min_fight_duration（最小时长）

**含义**: 多短的片段会被过滤掉

**影响**:
- 太小: 噪声片段多
- 太大: 短暂打架被忽略

**建议值**:
- 一般: 15-25 帧（0.5-0.8秒）
- 根据最短有效打架时长调整

### 调优策略

#### 策略A: 精确率优先（减少误报）

适用场景: 需要确保检测到的都是真打架

```bash
--window-size 40
--stride 20
--distance-threshold 120
--speed-threshold 60
--min-fight-duration 25
--conf 0.80
```

#### 策略B: 召回率优先（减少漏检）

适用场景: 不能遗漏任何打架片段

```bash
--window-size 25
--stride 8
--distance-threshold 80
--speed-threshold 40
--min-fight-duration 10
--conf 0.70
```

#### 策略C: 平衡策略

适用场景: 一般情况，追求F1最大

```bash
--window-size 30
--stride 15
--distance-threshold 100
--speed-threshold 50
--min-fight-duration 15
--conf 0.75
```

### 迭代调优流程

```
1. 使用默认参数运行
   ↓
2. 查看评估结果
   ↓
3. 分析错误类型
   ├─ FP多（误检）→ 使用策略A
   ├─ FN多（漏检）→ 使用策略B
   └─ 时间不准 → 减小stride
   ↓
4. 重新运行
   ↓
5. 重复直到满意
```

---

## 📈 评估指标解读

### 精确率 (Precision)

**公式**: TP / (TP + FP)

**含义**: 在所有预测为打架的片段中，真正是打架的比例

**高精确率意味着**: 
- 很少误报
- 系统说是打架，大概率就是

**应用场景**: 
- 自动报警系统
- 需要人工审核成本很高的场景

### 召回率 (Recall)

**公式**: TP / (TP + FN)

**含义**: 在所有真实打架片段中，被检测出来的比例

**高召回率意味着**: 
- 很少漏检
- 实际打架基本都能发现

**应用场景**: 
- 安全监控
- 不能遗漏任何打架事件

### F1分数 (F1-Score)

**公式**: 2 × (Precision × Recall) / (Precision + Recall)

**含义**: 精确率和召回率的调和平均

**高F1分数意味着**: 
- 综合性能好
- 精确率和召回率都不错

**应用场景**: 
- 一般评估
- 需要平衡误报和漏报

### IoU阈值

**含义**: 预测片段和GT片段的重叠程度

**例子**:
```
GT:      |-------|
Pred:       |-------|
IoU = 交集/并集 = 0.6

如果 IoU >= 0.5，算匹配成功（TP）
如果 IoU < 0.5，Pred算误检（FP），GT算漏检（FN）
```

**调整建议**:
- 严格评估: IoU = 0.7
- 一般评估: IoU = 0.5
- 宽松评估: IoU = 0.3

---

## 🐛 常见问题排查

### 问题1: 所有视频都没检测到打架

**可能原因**:
1. 参数阈值设置太高
2. 跟踪效果不好，目标ID频繁变化
3. 模型检测效果差

**排查方法**:
```bash
# 1. 检查跟踪效果
python track.py --source video.mp4 --weights best.pt --show

# 2. 大幅降低阈值测试
python track_with_fight_detection.py \
  --source video.mp4 \
  --distance-threshold 50 \
  --speed-threshold 20 \
  --min-fight-duration 5

# 3. 查看帧数据
# 在代码中添加print，查看detector.frame_data
```

### 问题2: 检测结果与GT完全不匹配

**可能原因**:
1. GT文件中视频名不匹配
2. 帧率不一致（GT用时间但fps错误）
3. 视频被截取或编辑过

**排查方法**:
```bash
# 1. 检查视频名
python -c "
import json
with open('gt.json') as f:
    data = json.load(f)
print('GT中的视频名:', list(data.keys()))
"

# 2. 检查帧率
ffprobe -v quiet -show_streams video.mp4 | grep r_frame_rate

# 3. 可视化对比
python visualize_results.py --video video.mp4 --pred pred.json --gt gt.json
```

### 问题3: 运行很慢

**优化方法**:
```bash
# 1. 使用GPU
--device 0

# 2. 跳帧处理
--vid-stride 2  # 每2帧处理1帧

# 3. 降低推理分辨率
--imgsz 416  # 默认640

# 4. 不保存可视化
# 去掉 --save 参数

# 5. 增大stride
--stride 20  # 减少窗口数量
```

### 问题4: 内存不足

**解决方法**:
```bash
# 1. 不要一次性处理太多视频
# 分批处理

# 2. 增大stride减少窗口
--stride 30

# 3. 减小window_size
--window-size 20

# 4. 在代码中添加定期清理
# 每处理N帧清理一次detector.frame_data
```

---

## 🎓 高级使用技巧

### 技巧1: 自定义打架判断逻辑

编辑 `track_with_fight_detection.py`，修改 `FightDetector.is_fighting_in_window`:

```python
def is_fighting_in_window(self, start_idx: int, end_idx: int):
    # ... 原有代码 ...
    
    # 添加自定义特征
    # 例如: 检查是否有猪被顶翻（bbox高度骤减）
    height_changes = []
    for i in range(1, len(window_frames)):
        for obj in window_frames[i]['objects']:
            prev_h = ... # 找上一帧同ID的高度
            curr_h = obj['size'][1]
            height_changes.append(abs(curr_h - prev_h) / prev_h)
    
    if height_changes:
        max_height_change = max(height_changes)
        if max_height_change > 0.3:  # 高度变化超过30%
            scores.append(1.0)
    
    # ... 继续原有代码 ...
```

### 技巧2: 导出Excel报告

```python
import pandas as pd
import json

# 读取评估结果
with open('batch_evaluation_results/overall_evaluation.json') as f:
    data = json.load(f)

# 转换为DataFrame
rows = []
for result in data['per_video_results']:
    rows.append({
        '视频': result['video'],
        '精确率': result['metrics']['precision'],
        '召回率': result['metrics']['recall'],
        'F1分数': result['metrics']['f1'],
        'TP': result['metrics']['tp'],
        'FP': result['metrics']['fp'],
        'FN': result['metrics']['fn']
    })

df = pd.DataFrame(rows)
df.to_excel('evaluation_results.xlsx', index=False)
print("已导出到 evaluation_results.xlsx")
```

### 技巧3: 批量生成可视化视频

```bash
#!/bin/bash
# save as: batch_visualize.sh

VIDEO_DIR="test_videos"
PRED_DIR="final_results"
OUTPUT_DIR="visualizations"
GT_FILE="ground_truth.json"

mkdir -p "$OUTPUT_DIR"

for video in "$VIDEO_DIR"/*.mp4; do
  basename=$(basename "$video" .mp4)
  pred_file="$PRED_DIR/${basename}_predictions.json"
  output_file="$OUTPUT_DIR/${basename}_visualized.mp4"
  
  if [ -f "$pred_file" ]; then
    echo "Processing $basename..."
    python visualize_results.py \
      --video "$video" \
      --pred "$pred_file" \
      --gt "$GT_FILE" \
      --output "$output_file" \
      --no-show
  fi
done

echo "All done!"
```

运行: `bash batch_visualize.sh`

### 技巧4: 参数网格搜索

```python
import subprocess
import json
import itertools

# 定义参数网格
param_grid = {
    'window_size': [20, 30, 40],
    'stride': [10, 15, 20],
    'distance_threshold': [80, 100, 120]
}

# 生成所有组合
keys = param_grid.keys()
values = param_grid.values()
combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]

results = []

for i, params in enumerate(combinations):
    print(f"\n测试组合 {i+1}/{len(combinations)}: {params}")
    
    # 运行评估
    cmd = [
        'python', 'track_with_fight_detection.py',
        '--source', 'test_video.mp4',
        '--gt-file', 'gt.json',
        '--window-size', str(params['window_size']),
        '--stride', str(params['stride']),
        '--distance-threshold', str(params['distance_threshold']),
        '--output-dir', f'grid_search_{i}'
    ]
    
    subprocess.run(cmd)
    
    # 读取结果
    eval_file = f'grid_search_{i}/test_video_evaluation.json'
    with open(eval_file) as f:
        eval_data = json.load(f)
    
    results.append({
        'params': params,
        'metrics': eval_data['metrics']
    })

# 找最佳参数
best = max(results, key=lambda x: x['metrics']['f1'])
print(f"\n最佳参数: {best['params']}")
print(f"F1分数: {best['metrics']['f1']:.4f}")

# 保存所有结果
with open('grid_search_results.json', 'w') as f:
    json.dump(results, f, indent=2)
```

---

## 📞 技术支持

### 文档资源

- **完整文档**: `README_fight_detection.md`
- **快速入门**: `QUICKSTART.md`
- **使用说明**: `使用说明.md`（本文件）

### 代码资源

- **示例GT**: `ground_truth_example.json`
- **核心代码**: `track_with_fight_detection.py`（有详细注释）

### 调试技巧

1. **查看中间数据**:在代码中添加 `print` 或 `breakpoint()`

2. **逐步运行**: 使用 `--show` 参数实时查看

3. **保存日志**: 重定向输出到文件
   ```bash
   python track_with_fight_detection.py ... 2>&1 | tee log.txt
   ```

---

## ✅ 检查清单

使用前确认:

- [ ] 已安装依赖: `pip install ultralytics opencv-python numpy`
- [ ] 模型权重文件存在
- [ ] 测试视频准备好
- [ ] GPU驱动正常（如果使用GPU）

开始标注前:

- [ ] 明确打架行为的定义
- [ ] 决定使用帧号还是时间（秒）
- [ ] 测试视频能正常播放

开始评估前:

- [ ] GT文件格式正确
- [ ] GT中的视频名与实际文件名完全一致
- [ ] 已在单个视频上测试过参数

---

**祝使用顺利！如有问题，请查看详细文档或检查代码注释。**

